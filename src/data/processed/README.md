# Processed Data Directory

This directory contains all processed data files generated by the data preparation and dataset creation pipeline.

## File Structure

### JSONL Files (Player Events)
- `game1_player_events.jsonl` - Game 1 data converted from CSV to JSONL format
- `game1_player_events_train.jsonl` - 80% training split of Game 1 players
- `game1_player_events_eval.jsonl` - 20% evaluation split of Game 1 players
- `playerLogs_game2_playerbasedlines_train.jsonl` - 80% training split of Game 2 players
- `playerLogs_game2_playerbasedlines_eval.jsonl` - 20% evaluation split of Game 2 players

### Labeled Datasets
- `game1_DS1_labeled.jsonl` - Game 1 training dataset with churn labels
- `game1_DS2_labeled.jsonl` - Game 1 evaluation dataset with churn labels
- `game2_DS1_labeled.jsonl` - Game 2 training dataset with churn labels
- `game2_DS2_labeled.jsonl` - Game 2 evaluation dataset with churn labels

### Statistics Files
- `*_stats.json` - Statistics for each labeled dataset (churn rates, player counts, etc.)
- `pipeline_results.json` - Overall pipeline execution results and file mappings

## Data Formats

### Player Events JSONL Format
Each line contains a JSON object with:
```json
{
  "device_id": "string",  // or "uid" for Game 2
  "records": [
    {
      "time": integer,      // Unix timestamp (seconds for Game 1, milliseconds for Game 2)
      "event": "string",    // Event type (e.g., "play", "softPurchase")
      "score": integer,     // Score (for play events)
      // Additional fields for Game 2 events
    }
  ]
}
```

### Labeled Dataset Format
Each line contains a JSON object with:
```json
{
  "player_id": "string",
  "observation_records": [...],      // Events in 5-day observation period
  "churn_period_records": [...],     // Events in 10-day churn period
  "churned": boolean,                // True if no events in churn period
  "op_start": "ISO datetime",        // Observation period start
  "op_end": "ISO datetime",          // Observation period end
  "cp_start": "ISO datetime",        // Churn period start
  "cp_end": "ISO datetime",          // Churn period end
  "op_event_count": integer,         // Number of events in observation period
  "cp_event_count": integer          // Number of events in churn period
}
```

## Processing Pipeline

1. **Data Preparation** (`data_preparation.py`)
   - Converts Game 1 CSV to JSONL format
   - Splits both games into 80/20 train/eval sets

2. **Dataset Creation** (`dataset_creation.py`)
   - Defines 5-day observation period from first event
   - Defines 10-day churn prediction period after observation
   - Labels players as churned if no events in churn period
   - Creates DS1 (training) and DS2 (evaluation) datasets

## Usage

To regenerate all processed data:
```bash
python src/run_data_pipeline.py
```

To inspect the created datasets:
```bash
python src/inspect_datasets.py
``` 